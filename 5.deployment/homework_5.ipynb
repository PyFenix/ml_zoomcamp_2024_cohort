{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Zoomcamp Cohort 2024\n",
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipenv\n",
      "  Downloading pipenv-2024.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: certifi in /home/lqueiros/projects/ml_zoomcamp_2024_cohort/.venv/lib/python3.10/site-packages (from pipenv) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=22 in /home/lqueiros/projects/ml_zoomcamp_2024_cohort/.venv/lib/python3.10/site-packages (from pipenv) (24.1)\n",
      "Collecting setuptools>=67 (from pipenv)\n",
      "  Using cached setuptools-75.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting virtualenv>=20.24.2 (from pipenv)\n",
      "  Downloading virtualenv-20.27.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.24.2->pipenv)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.24.2->pipenv)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /home/lqueiros/projects/ml_zoomcamp_2024_cohort/.venv/lib/python3.10/site-packages (from virtualenv>=20.24.2->pipenv) (4.3.6)\n",
      "Downloading pipenv-2024.2.0-py3-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-75.2.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading virtualenv-20.27.1-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: distlib, setuptools, filelock, virtualenv, pipenv\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 63.2.0\n",
      "    Uninstalling setuptools-63.2.0:\n",
      "      Successfully uninstalled setuptools-63.2.0\n",
      "Successfully installed distlib-0.3.9 filelock-3.16.1 pipenv-2024.2.0 setuptools-75.2.0 virtualenv-20.27.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mpipenv\u001b[0m, version 2024.2.0\n"
     ]
    }
   ],
   "source": [
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.5.2\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "> **Note**: you should create an empty folder for homework\n",
    "and do it there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mCourtesy Notice\u001b[0m:\n",
      "Pipenv found itself running within a virtual environment,  so it will \n",
      "automatically use that environment, instead of  creating its own for any \n",
      "project. You can set\n",
      "\u001b[1;33mPIPENV_IGNORE_VIRTUALENVS\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m1\u001b[0m to force pipenv to ignore that environment and \n",
      "create  its own instead.\n",
      "You can set \u001b[1;33mPIPENV_VERBOSITY\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m-1\u001b[0m to suppress this warning.\n",
      "\u001b[1mrequirements.txt\u001b[0m found in \u001b[1;33m/home/lqueiros/projects/ml_zoomcamp_2024_cohort\u001b[0m \n",
      "instead of \u001b[1mPipfile\u001b[0m! Converting...\n",
      "\u001b[2K✔ Success! Importing requirements.....\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Importing requirements...\n",
      "\u001b[1A\u001b[2K\u001b[1;31mWarning\u001b[0m: Your \u001b[1mPipfile\u001b[0m now contains pinned versions, if your \u001b[1mrequirements.txt\u001b[0m \n",
      "did. \n",
      "We recommend updating your \u001b[1mPipfile\u001b[0m to specify the \u001b[1m\"*\"\u001b[0m version, instead.\n",
      "\u001b[1mPipfile.lock not found, creating\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[1mUpdated Pipfile.lock (7a99f77513df7b3896e2ccae5c6a87d6ce33192610a5e7b64beb510b5803fba7)!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1;32mInstalling scikit-learn==1.5.2...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KTo activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock (c3fff3)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock (c3fff3)...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pipenv install scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['job', 'duration', 'poutcome']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2024/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2024/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2024/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-28 21:05:57--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2024/05-deployment/homework/model1.bin\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 850 [application/octet-stream]\n",
      "Saving to: ‘model1.bin’\n",
      "\n",
      "model1.bin          100%[===================>]     850  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-28 21:05:58 (25.5 MB/s) - ‘model1.bin’ saved [850/850]\n",
      "\n",
      "--2024-10-28 21:05:59--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2024/05-deployment/homework/dv.bin\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 560 [application/octet-stream]\n",
      "Saving to: ‘dv.bin’\n",
      "\n",
      "dv.bin              100%[===================>]     560  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-28 21:05:59 (20.6 MB/s) - ‘dv.bin’ saved [560/560]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREFIX=\"https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2024/05-deployment/homework\"\n",
    "!wget $PREFIX/model1.bin\n",
    "!wget $PREFIX/dv.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a subscription? \n",
    "\n",
    "* 0.359\n",
    "* 0.559\n",
    "* 0.759\n",
    "* 0.959\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "3d8bb28974e55edefa000fe38fd3ed12  model1.bin\n",
    "7d37616e00aa80f2152b8b0511fc2dff  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DictVectorizer\n",
    "with open('dv.bin', 'rb') as f_in:\n",
    "    dv = pickle.load(f_in)\n",
    "\n",
    "# Load the Logistic Regression model\n",
    "with open('model1.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dv.transform([client])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that the client will get a subscription is: 0.759\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X)[0, 1]\n",
    "print(f\"The probability that the client will get a subscription is: {y_pred:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"student\", \"duration\": 280, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a subscription?\n",
    "\n",
    "* 0.335\n",
    "* 0.535\n",
    "* 0.735\n",
    "* 0.935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md). \n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.11.5-slim`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.11.5-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.11.5-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.11.5-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.11.5-slim`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 45 MB\n",
    "* 130 MB\n",
    "* 245 MB\n",
    "* 330 MB\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo dockerd &\n",
    "# !docker pull svizor/zoomcamp-model:3.11.5-slim\n",
    "# !docker images\n",
    "# svizor/zoomcamp-model              3.11.5-slim       975e7bdca086   9 days ago     130MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM svizor/zoomcamp-model:3.11.5-slim\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with Gunicorn \n",
    "\n",
    "After that, you can build your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a subscription now?\n",
    "\n",
    "* 0.287\n",
    "* 0.530\n",
    "* 0.757\n",
    "* 0.960\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker build -t predict_churn_app .\n",
    "# !docker run -p 8000:8000 predict_churn_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
